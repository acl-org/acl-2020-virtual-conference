[{"card_image_alt_text":"A representative figure from paper main.158","card_image_path":"static/images/papers/main.158.png","content":{"abstract":"While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.","authors":["Jennifer Hu","Jon Gauthier","Peng Qian","Ethan Wilcox","Roger Levy"],"demo_url":"","keywords":["Systematic Generalization","Syntactic Generalization","syntactic generalizations","Neural Models"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.158.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 13:00:00 GMT","session_name":"3A","start_time":"Mon, 06 Jul 2020 12:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.158","similar_paper_uids":["main.158","tacl.1892","main.303","main.179","srw.28"],"title":"A Systematic Assessment of Syntactic Generalization in Neural Language Models","tldr":"While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Further...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.158","id":"main.158","presentation_id":"38929407"},{"card_image_alt_text":"A representative figure from paper main.159","card_image_path":"static/images/papers/main.159.png","content":{"abstract":"Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995): that neural models may learn to extend not the regular, but the most frequent class \u2014 and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.","authors":["Kate McCurdy","Sharon Goldwater","Adam Lopez"],"demo_url":"","keywords":["minority-class generalization","Encoder-Decoder Networks","Cognitive Models","artificial networks"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.159.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 13:00:00 GMT","session_name":"3A","start_time":"Mon, 06 Jul 2020 12:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.159","similar_paper_uids":["main.159","main.177","main.698","main.597","main.142"],"title":"Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals","tldr":"Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior w...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.159","id":"main.159","presentation_id":"38929385"},{"card_image_alt_text":"A representative figure from paper main.161","card_image_path":"static/images/papers/main.161.png","content":{"abstract":"Suspense is a crucial ingredient of narrative fiction, engaging readers and making stories compelling. While there is a vast theoretical literature on suspense, it is computationally not well understood. We compare two ways for modelling suspense: surprise, a backward-looking measure of how unexpected the current state is given the story so far; and uncertainty reduction, a forward-looking measure of how unexpected the continuation of the story is. Both can be computed either directly over story representations or over their probability distributions. We propose a hierarchical language model that encodes stories and computes surprise and uncertainty reduction. Evaluating against short stories annotated with human suspense judgements, we find that uncertainty reduction over representations is the best predictor, resulting in near human accuracy. We also show that uncertainty reduction can be used to predict suspenseful events in movie synopses.","authors":["David Wilmot","Frank Keller"],"demo_url":"","keywords":["Uncertainty Reduction","narrative fiction","surprise reduction","Neural Representation"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.161.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 13:00:00 GMT","session_name":"3A","start_time":"Mon, 06 Jul 2020 12:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.161","similar_paper_uids":["main.161","main.178","main.623","tacl.1886","main.162"],"title":"Suspense in Short Stories is Predicted By Uncertainty Reduction over Neural Story Representation","tldr":"Suspense is a crucial ingredient of narrative fiction, engaging readers and making stories compelling. While there is a vast theoretical literature on suspense, it is computationally not well understood. We compare two ways for modelling suspense: su...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.161","id":"main.161","presentation_id":"38928796"},{"card_image_alt_text":"A representative figure from paper main.160","card_image_path":"static/images/papers/main.160.png","content":{"abstract":"With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.","authors":["Jordan Kodner","Nitish Gupta"],"demo_url":"","keywords":["Overestimation Representation","Neural Models","models representations","non-syntactic models"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.160.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 13:00:00 GMT","session_name":"3A","start_time":"Mon, 06 Jul 2020 12:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.160","similar_paper_uids":["main.160","main.463","main.375","main.387","main.641"],"title":"Overestimation of Syntactic Representation in Neural Language Models","tldr":"With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to prob...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.160","id":"main.160","presentation_id":"38928906"},{"card_image_alt_text":"A representative figure from paper main.176","card_image_path":"static/images/papers/main.176.png","content":{"abstract":"In recent years there has been a burgeoning interest in the use of computational methods to distinguish between elicited speech samples produced by patients with dementia, and those from healthy controls. The difference between perplexity estimates from two neural language models (LMs) - one trained on transcripts of speech produced by healthy participants and one trained on those with dementia - as a single feature for diagnostic classification of unseen transcripts has been shown to produce state-of-the-art performance. However, little is known about why this approach is effective, and on account of the lack of case/control matching in the most widely-used evaluation set of transcripts (DementiaBank), it is unclear if these approaches are truly diagnostic, or are sensitive to other variables. In this paper, we interrogate neural LMs trained on participants with and without dementia by using synthetic narratives previously developed to simulate progressive semantic dementia by manipulating lexical frequency. We find that perplexity of neural LMs is strongly and differentially associated with lexical frequency, and that using a mixture model resulting from interpolating control and dementia LMs improves upon the current state-of-the-art for models trained on transcript text exclusively.","authors":["Trevor Cohen","Serguei Pakhomov"],"demo_url":"","keywords":["Lexical Deficits","diagnostic classification","Neural Models","computational methods"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.176.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.176","similar_paper_uids":["main.176","main.1","main.8","main.587","srw.116"],"title":"A Tale of Two Perplexities: Sensitivity of Neural Language Models to Lexical Retrieval Deficits in Dementia of the Alzheimer\u2019s Type","tldr":"In recent years there has been a burgeoning interest in the use of computational methods to distinguish between elicited speech samples produced by patients with dementia, and those from healthy controls. The difference between perplexity estimates f...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.176","id":"main.176","presentation_id":"38929174"},{"card_image_alt_text":"A representative figure from paper main.162","card_image_path":"static/images/papers/main.162.png","content":{"abstract":"Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only predictions (i.e. predicting the time to read a single word). We seek to extend these works by examining whether or not document level predictions are effective, given additional information such as subject matter, font characteristics, and readability metrics. We perform a novel experiment to examine how different features of text contribute to the time it takes to read, distributing and collecting data from over a thousand participants. We then employ a large number of machine learning methods to predict a user's reading time. We find that despite extensive research showing that word level reading time can be most effectively predicted by neural networks, larger scale text can be easily and most accurately predicted by one factor, the number of words.","authors":["Orion Weller","Jordan Hildebrandt","Ilya Reznik","Christopher Challis","E. Shannon Tass","Quinn Snell","Kevin Seppi"],"demo_url":"","keywords":["Exploration Prediction","Predicting time","human processing","machine methods"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.162.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 13:00:00 GMT","session_name":"3A","start_time":"Mon, 06 Jul 2020 12:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.162","similar_paper_uids":["main.162","main.473","main.507","main.668","main.86"],"title":"You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction","tldr":"Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only pre...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.162","id":"main.162","presentation_id":"38929163"},{"card_image_alt_text":"A representative figure from paper main.177","card_image_path":"static/images/papers/main.177.png","content":{"abstract":"Recently, there has been much interest in the question of whether deep natural language understanding (NLU) models exhibit systematicity, generalizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models do not learn systematically. We examine the notion of systematicity from a linguistic perspective, defining a set of probing tasks and a set of metrics to measure systematic behaviour. We also identify ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we perform a series of experiments in the setting of natural language inference (NLI). We provide evidence that current state-of-the-art NLU systems do not generalize systematically, despite overall high performance.","authors":["Emily Goodwin","Koustuv Sinha","Timothy J. O'Donnell"],"demo_url":"","keywords":["Probing Systematicity","probing tasks","generalization","natural inference"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.177.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.177","similar_paper_uids":["main.177","main.543","main.159","cl.1552","main.561"],"title":"Probing Linguistic Systematicity","tldr":"Recently, there has been much interest in the question of whether deep natural language understanding (NLU) models exhibit systematicity, generalizing such that units like words make consistent contributions to the meaning of the sentences in which t...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.177","id":"main.177","presentation_id":"38929277"},{"card_image_alt_text":"A representative figure from paper main.1","card_image_path":"static/images/papers/main.1.png","content":{"abstract":"Speech directed to children differs from adult-directed speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.","authors":["Lieke Gelderloos","Grzegorz Chrupa\u0142a","Afra Alishahi"],"demo_url":"","keywords":["Human acquisition","Human research","CDS","ADS"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.1.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 06:00:00 GMT","session_name":"1A","start_time":"Mon, 06 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.1","similar_paper_uids":["main.1","main.176","main.633","main.351","srw.116"],"title":"Learning to Understand Child-directed and Adult-directed Speech","tldr":"Speech directed to children differs from adult-directed speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acqu...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.1","id":"main.1","presentation_id":"38929437"},{"card_image_alt_text":"A representative figure from paper main.2","card_image_path":"static/images/papers/main.2.png","content":{"abstract":"Accurately diagnosing depression is difficult-- requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a model that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to define high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.","authors":["Alex Rinaldi","Jean Fox Tree","Snigdha Chaturvedi"],"demo_url":"","keywords":["Depression Interviews","depression","assessments","analysis"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.2.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 06:00:00 GMT","session_name":"1A","start_time":"Mon, 06 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 10:00:00 GMT","session_name":"2B","start_time":"Mon, 06 Jul 2020 09:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.2","similar_paper_uids":["main.2","main.694","main.437","main.270","cl.1552"],"title":"Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts","tldr":"Accurately diagnosing depression is difficult-- requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more in...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.2","id":"main.2","presentation_id":"38928967"},{"card_image_alt_text":"A representative figure from paper main.179","card_image_path":"static/images/papers/main.179.png","content":{"abstract":"A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.","authors":["Forrest Davis","Marten van Schijndel"],"demo_url":"","keywords":["production","Recurrent Always","language models","RNN LMs"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.179.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.179","similar_paper_uids":["main.179","main.158","main.173","main.309","main.263"],"title":"Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment","tldr":"A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.179","id":"main.179","presentation_id":"38929008"},{"card_image_alt_text":"A representative figure from paper main.178","card_image_path":"static/images/papers/main.178.png","content":{"abstract":"We investigate the use of NLP as a measure of the cognitive processes involved in storytelling, contrasting imagination and recollection of events. To facilitate this, we collect and release Hippocorpus, a dataset of 7,000 stories about imagined and recalled events. We introduce a measure of narrative flow and use this to examine the narratives for imagined and recalled events. Additionally, we measure the differential recruitment of knowledge attributed to semantic memory versus episodic memory (Tulving, 1972) for imagined and recalled storytelling by comparing the frequency of descriptions of general commonsense events with more specific realis events. Our analyses show that imagined stories have a substantially more linear narrative flow, compared to recalled stories in which adjacent sentences are more disconnected. In addition, while recalled stories rely more on autobiographical events based on episodic memory, imagined stories express more commonsense knowledge based on semantic memory. Finally, our measures reveal the effect of narrativization of memories in stories (e.g., stories about frequently recalled memories flow more linearly; Bartlett, 1932). Our findings highlight the potential of using NLP tools to study the traces of human cognition in language.","authors":["Maarten Sap","Eric Horvitz","Yejin Choi","Noah A. Smith","James Pennebaker"],"demo_url":"","keywords":["Imagination","storytelling","narrativization memories","Recollection"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.178.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.178","similar_paper_uids":["main.178","main.161","tacl.1886","main.233","main.481"],"title":"Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models","tldr":"We investigate the use of NLP as a measure of the cognitive processes involved in storytelling, contrasting imagination and recollection of events. To facilitate this, we collect and release Hippocorpus, a dataset of 7,000 stories about imagined and ...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.178","id":"main.178","presentation_id":"38929213"},{"card_image_alt_text":"A representative figure from paper main.180","card_image_path":"static/images/papers/main.180.png","content":{"abstract":"Recent work has found evidence that natural languages are shaped by pressures for efficient communication \u2014 e.g. the more contextually predictable a word is, the fewer speech sounds or syllables it has (Piantadosi et al. 2011). Research on the degree to which speech and language are shaped by pressures for effective communication \u2014 robustness in the face of noise and uncertainty \u2014 has been more equivocal. We develop a measure of contextual confusability during word recognition based on psychoacoustic data. Applying this measure to naturalistic speech corpora, we find evidence suggesting that speakers alter their productions to make contextually more confusable words easier to understand.","authors":["Eric Meinhardt","Eric Bakovic","Leon Bergen"],"demo_url":"","keywords":["word recognition","contextually words","speech sounds","noise"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.180.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.180","similar_paper_uids":["main.180","srw.16","main.244","main.97","main.493"],"title":"Speakers enhance contextually confusable words","tldr":"Recent work has found evidence that natural languages are shaped by pressures for efficient communication \u2014 e.g. the more contextually predictable a word is, the fewer speech sounds or syllables it has (Piantadosi et al. 2011). Research on the degree...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.180","id":"main.180","presentation_id":"38929286"},{"card_image_alt_text":"A representative figure from paper main.181","card_image_path":"static/images/papers/main.181.png","content":{"abstract":"We take up the scientific question of what determines the preferred order of adjectives in English, in phrases such as big blue box where multiple adjectives modify a following noun. We implement and test four quantitative theories, all of which are theoretically motivated in terms of efficiency in human language production and comprehension. The four theories we test are subjectivity (Scontras et al., 2017), information locality (Futrell, 2019), integration cost (Dyer, 2017), and information gain, which we introduce. We evaluate theories based on their ability to predict orders of unseen adjectives in hand-parsed and automatically-parsed dependency treebanks. We find that subjectivity, information locality, and information gain are all strong predictors, with some evidence for a two-factor account, where subjectivity and information gain reflect a factor involving semantics, and information locality reflects collocational preferences.","authors":["Richard Futrell","William Dyer","Greg Scontras"],"demo_url":"","keywords":["efficiency-based theories","order adjectives","information locality","integration cost"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.181.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 18:00:00 GMT","session_name":"4A","start_time":"Mon, 06 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 22:00:00 GMT","session_name":"5B","start_time":"Mon, 06 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.181","similar_paper_uids":["main.181","main.406","main.179","main.384","main.584"],"title":"What determines the order of adjectives in English? Comparing efficiency-based theories using dependency treebanks","tldr":"We take up the scientific question of what determines the preferred order of adjectives in English, in phrases such as big blue box where multiple adjectives modify a following noun. We implement and test four quantitative theories, all of which are ...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"main.181","id":"main.181","presentation_id":"38929156"},{"card_image_alt_text":"A representative figure from paper tacl.1915","card_image_path":"static/images/papers/tacl.1915.png","content":{"abstract":"We study the influence of context on sentence acceptability. First we compare the acceptability ratings of sentences judged in isolation, with a relevant context, and with an irrelevant context. Our results show that context induces a cognitive load for humans, which compresses the distribution of ratings. Moreover, in relevant contexts we observe a discourse coherence effect which uniformly raises acceptability. Next, we test unidirectional and bidirectional language models in their ability to predict acceptability ratings. The bidirectional models show very promising results, with the best model achieving a new state-of-the-art for unsupervised acceptability prediction. The two sets of experiments provide insights into the cognitive aspects of sentence processing and central issues in the computational modelling of text and discourse.","authors":["Jey Han Lau","Carlos Santos Armendariz","Matthew Purver","Chang Shu","Shalom Lappin"],"demo_url":"","keywords":["unsupervised prediction","cognitive processing","computational discourse","unidirectional models"],"paper_type":"TACL","pdf_url":"https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00315","sessions":[{"end_time":"Mon, 06 Jul 2020 06:00:00 GMT","session_name":"1A","start_time":"Mon, 06 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 10:00:00 GMT","session_name":"2B","start_time":"Mon, 06 Jul 2020 09:00:00 GMT","zoom_link":""}],"share_url":"https://www.mitpressjournals.org/doi/10.1162/tacl_a_00315","similar_paper_uids":["tacl.1915","srw.22","tacl.1780","main.530","tacl.1811"],"title":"How Furiously Can Colourless Green Ideas Sleep? Sentence Acceptability in Context","tldr":"We study the influence of context on sentence acceptability. First we compare the acceptability ratings of sentences judged in isolation, with a relevant context, and with an irrelevant context. Our results show that context induces a cognitive load ...","track":"Cognitive Modeling and Psycholinguistics"},"forum":"tacl.1915","id":"tacl.1915","presentation_id":"38929511"}]
