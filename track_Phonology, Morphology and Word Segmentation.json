[{"card_image_alt_text":"A representative figure from paper main.598","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.598.png","content":{"abstract":"We propose the task of unsupervised morphological paradigm completion. Given only raw text and a lemma list, the task consists of generating the morphological paradigms, i.e., all inflected forms, of the lemmas. From a natural language processing (NLP) perspective, this is a challenging unsupervised task, and high-performing systems have the potential to improve tools for low-resource languages or to assist linguistic annotators. From a cognitive science perspective, this can shed light on how children acquire morphological knowledge. We further introduce a system for the task, which generates morphological paradigms via the following steps: (i) EDIT TREE retrieval, (ii) additional lemma retrieval, (iii) paradigm size discovery, and (iv) inflection generation. We perform an evaluation on 14 typologically diverse languages. Our system outperforms trivial baselines with ease and, for some languages, even obtains a higher accuracy than minimally supervised systems.","authors":["Huiming Jin","Liwei Cai","Yihui Peng","Chen Xia","Arya McCarthy","Katharina Kann"],"demo_url":"","keywords":["unsupervised completion","unsupervised task","linguistic annotators","EDIT retrieval"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.598.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 07:00:00 GMT","session_name":"11B","start_time":"Wed, 08 Jul 2020 06:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.598","similar_paper_uids":["main.598","main.596","main.115","main.733","main.695"],"title":"Unsupervised Morphological Paradigm Completion","tldr":"We propose the task of unsupervised morphological paradigm completion. Given only raw text and a lemma list, the task consists of generating the morphological paradigms, i.e., all inflected forms, of the lemmas. From a natural language processing (NL...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.598","id":"main.598","presentation_id":"38929159"},{"card_image_alt_text":"A representative figure from paper main.649","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.649.png","content":{"abstract":"We present the first study that examines the evolution of morphological families, i.e., sets of morphologically related words such as \u201ctrump\u201d, \u201cantitrumpism\u201d, and \u201cdetrumpify\u201d, in social media. We introduce the novel task of Morphological Family Expansion Prediction (MFEP) as predicting the increase in the size of a morphological family. We create a ten-year Reddit corpus as a benchmark for MFEP and evaluate a number of baselines on this benchmark. Our experiments demonstrate very good performance on MFEP.","authors":["Valentin Hofmann","Janet Pierrehumbert","Hinrich Sch\u00fctze"],"demo_url":"","keywords":["evolution families","Morphological MFEP","MFEP","Growth Families"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.649.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.649","similar_paper_uids":["main.649","main.209","main.596","main.587","main.374"],"title":"Predicting the Growth of Morphological Families from Social and Linguistic Factors","tldr":"We present the first study that examines the evolution of morphological families, i.e., sets of morphologically related words such as \u201ctrump\u201d, \u201cantitrumpism\u201d, and \u201cdetrumpify\u201d, in social media. We introduce the novel task of Morphological Family Expa...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.649","id":"main.649","presentation_id":"38929182"},{"card_image_alt_text":"A representative figure from paper main.106","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.106.png","content":{"abstract":"There has been little work on modeling the morphological well-formedness (MWF) of derivatives, a problem judged to be complex and difficult in linguistics. We present a graph auto-encoder that learns embeddings capturing information about the compatibility of affixes and stems in derivation. The auto-encoder models MWF in English surprisingly well by combining syntactic and semantic information with associative information from the mental lexicon.","authors":["Valentin Hofmann","Hinrich Sch\u00fctze","Janet Pierrehumbert"],"demo_url":"","keywords":["Graph Morphology","graph auto-encoder","auto-encoder MWF","MWF"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.106.pdf","sessions":[{"end_time":"Mon, 06 Jul 2020 09:00:00 GMT","session_name":"2A","start_time":"Mon, 06 Jul 2020 08:00:00 GMT","zoom_link":""},{"end_time":"Mon, 06 Jul 2020 14:00:00 GMT","session_name":"3B","start_time":"Mon, 06 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.106","similar_paper_uids":["main.106","main.67","main.322","main.571","demo.116"],"title":"A Graph Auto-encoder Model of Derivational Morphology","tldr":"There has been little work on modeling the morphological well-formedness (MWF) of derivatives, a problem judged to be complex and difficult in linguistics. We present a graph auto-encoder that learns embeddings capturing information about the compati...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.106","id":"main.106","presentation_id":"38929053"},{"card_image_alt_text":"A representative figure from paper main.648","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.648.png","content":{"abstract":"Simplified Chinese to Traditional Chinese character conversion is a common preprocessing step in Chinese NLP. Despite this, current approaches have insufficient performance because they do not take into account that a simplified Chinese character can correspond to multiple traditional characters. Here, we propose a model that can disambiguate between mappings and convert between the two scripts. The model is based on subword segmentation, two language models, as well as a method for mapping between subword sequences. We further construct benchmark datasets for topic classification and script conversion. Our proposed method outperforms previous Chinese Character conversion approaches by 6 points in accuracy. These results are further confirmed in a downstream application, where 2kenize is used to convert pretraining dataset for topic classification. An error analysis reveals that our method's particular strengths are in dealing with code mixing and named entities.","authors":["- Pranav A","Isabelle Augenstein"],"demo_url":"","keywords":["Chinese Conversion","Chinese NLP","mapping sequences","topic classification"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.648.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.648","similar_paper_uids":["main.648","main.315","main.145","main.737","main.81"],"title":"2kenize: Tying Subword Sequences for Chinese Script Conversion","tldr":"Simplified Chinese to Traditional Chinese character conversion is a common preprocessing step in Chinese NLP. Despite this, current approaches have insufficient performance because they do not take into account that a simplified Chinese character can...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.648","id":"main.648","presentation_id":"38928985"},{"card_image_alt_text":"A representative figure from paper main.737","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.737.png","content":{"abstract":"Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into Latin character sets found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languages---namely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our model directly on romanized data from two languages: Egyptian Arabic and Russian. We demonstrate that adding inductive bias through phonetic and visual priors on character mappings substantially improves the model's performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new dataset of romanized Russian, collected from a Russian social network website and partially annotated for our experiments.","authors":["Maria Ryskina","Matthew R. Gormley","Taylor Berg-Kirkpatrick"],"demo_url":"","keywords":["Decipherment Romanization","Informal romanization","idiosyncratic process","noisy-channel model"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.737.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.737","similar_paper_uids":["main.737","main.648","main.736","main.138","main.81"],"title":"Phonetic and Visual Priors for Decipherment of Informal Romanization","tldr":"Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into Latin character sets found on common keyboards. Character substitution choices differ between users but have ...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.737","id":"main.737","presentation_id":"38929400"},{"card_image_alt_text":"A representative figure from paper main.736","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.736.png","content":{"abstract":"The written forms of Semitic languages are both highly ambiguous and morphologically rich: a word can have multiple interpretations and is one of many inflected forms of the same concept or lemma. This is further exacerbated for dialectal content, which is more prone to noise and lacks a standard orthography. The morphological features can be lexicalized, like lemmas and diacritized forms, or non-lexicalized, like gender, number, and part-of-speech tags, among others. Joint modeling of the lexicalized and non-lexicalized features can identify more intricate morphological patterns, which provide better context modeling, and further disambiguate ambiguous lexical choices. However, the different modeling granularity can make joint modeling more difficult. Our approach models the different features jointly, whether lexicalized (on the character-level), or non-lexicalized (on the word-level). We use Arabic as a test case, and achieve state-of-the-art results for Modern Standard Arabic with 20% relative error reduction, and Egyptian Arabic with 11% relative error reduction.","authors":["Nasser Zalmout","Nizar Habash"],"demo_url":"","keywords":["Joint features","joint modeling","Lemmatization","Normalization"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.736.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.736","similar_paper_uids":["main.736","main.732","srw.98","main.737","main.240"],"title":"Joint Diacritization, Lemmatization, Normalization, and Fine-Grained Morphological Tagging","tldr":"The written forms of Semitic languages are both highly ambiguous and morphologically rich: a word can have multiple interpretations and is one of many inflected forms of the same concept or lemma. This is further exacerbated for dialectal content, wh...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.736","id":"main.736","presentation_id":"38928975"},{"card_image_alt_text":"A representative figure from paper main.695","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.695.png","content":{"abstract":"This work treats the paradigm discovery problem (PDP), the task of learning an inflectional morphological system from unannotated sentences. We formalize the PDP and develop evaluation metrics for judging systems. Using currently available resources, we construct datasets for the task. We also devise a heuristic benchmark for the PDP and report empirical results on five diverse languages. Our benchmark system first makes use of word embeddings and string similarity to cluster forms by cell and by paradigm. Then, we bootstrap a neural transducer on top of the clustered data to predict words to realize the empty paradigm slots. An error analysis of our system suggests clustering by cell across different inflection classes is the most pressing challenge for future work.","authors":["Alexander Erdmann","Micha Elsner","Shijie Wu","Ryan Cotterell","Nizar Habash"],"demo_url":"","keywords":["Paradigm Problem","judging systems","PDP","inflectional system"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.695.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.695","similar_paper_uids":["main.695","main.480","main.598","main.116","main.733"],"title":"The Paradigm Discovery Problem","tldr":"This work treats the paradigm discovery problem (PDP), the task of learning an inflectional morphological system from unannotated sentences. We formalize the PDP and develop evaluation metrics for judging systems. Using currently available resources,...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.695","id":"main.695","presentation_id":"38928868"},{"card_image_alt_text":"A representative figure from paper main.734","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.734.png","content":{"abstract":"Contextual features always play an important role in Chinese word segmentation (CWS). Wordhood information, being one of the contextual features, is proved to be useful in many conventional character-based segmenters. However, this feature receives less attention in recent neural models and it is also challenging to design a framework that can properly integrate wordhood information from different wordhood measures to existing neural frameworks. In this paper, we therefore propose a neural framework, WMSeg, which uses memory networks to incorporate wordhood information with several popular encoder-decoder combinations for CWS. Experimental results on five benchmark datasets indicate the memory mechanism successfully models wordhood information for neural segmenters and helps WMSeg achieve state-of-the-art performance on all those datasets. Further experiments and analyses also demonstrate the robustness of our proposed framework with respect to different wordhood measures and the efficiency of wordhood information in cross-domain experiments.","authors":["Yuanhe Tian","Yan Song","Fei Xia","Tong Zhang","Yonggang Wang"],"demo_url":"","keywords":["Chinese Segmentation","character-based segmenters","cross-domain experiments","Wordhood Networks"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.734.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.734","similar_paper_uids":["main.734","main.58","main.315","main.595","main.528"],"title":"Improving Chinese Word Segmentation with Wordhood Memory Networks","tldr":"Contextual features always play an important role in Chinese word segmentation (CWS). Wordhood information, being one of the contextual features, is proved to be useful in many conventional character-based segmenters. However, this feature receives l...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.734","id":"main.734","presentation_id":"38928921"},{"card_image_alt_text":"A representative figure from paper main.735","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.735.png","content":{"abstract":"Chinese word segmentation (CWS) and part-of-speech (POS) tagging are important fundamental tasks for Chinese language processing, where joint learning of them is an effective one-step solution for both tasks. Previous studies for joint CWS and POS tagging mainly follow the character-based tagging paradigm with introducing contextual information such as n-gram features or sentential representations from recurrent neural models. However, for many cases, the joint tagging needs not only modeling from context features but also knowledge attached to them (e.g., syntactic relations among words); limited efforts have been made by existing research to meet such needs. In this paper, we propose a neural model named TwASP for joint CWS and POS tagging following the character-based sequence labeling paradigm, where a two-way attention mechanism is used to incorporate both context feature and their corresponding syntactic knowledge for each input character. Particularly, we use existing language processing toolkits to obtain the auto-analyzed syntactic knowledge for the context, and the proposed attention module can learn and benefit from them although their quality may not be perfect. Our experiments illustrate the effectiveness of the two-way attentions for joint CWS and POS tagging, where state-of-the-art performance is achieved on five benchmark datasets.","authors":["Yuanhe Tian","Yan Song","Xiang Ao","Fei Xia","Xiaojun Quan","Tong Zhang","Yonggang Wang"],"demo_url":"","keywords":["Chinese Segmentation","Part-of-speech Tagging","Chinese processing","joint tagging"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.735.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.735","similar_paper_uids":["main.735","main.58","tacl.1876","main.732","main.609"],"title":"Joint Chinese Word Segmentation and Part-of-speech Tagging via Two-way Attentions of Auto-analyzed Knowledge","tldr":"Chinese word segmentation (CWS) and part-of-speech (POS) tagging are important fundamental tasks for Chinese language processing, where joint learning of them is an effective one-step solution for both tasks. Previous studies for joint CWS and POS ta...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.735","id":"main.735","presentation_id":"38929084"},{"card_image_alt_text":"A representative figure from paper main.696","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.696.png","content":{"abstract":"Hindi grapheme-to-phoneme (G2P) conversion is mostly trivial, with one exception: whether a schwa represented in the orthography is pronounced or unpronounced (deleted). Previous work has attempted to predict schwa deletion in a rule-based fashion using prosodic or phonetic analysis. We present the first statistical schwa deletion classifier for Hindi, which relies solely on the orthography as the input and outperforms previous approaches. We trained our model on a newly-compiled pronunciation lexicon extracted from various online dictionaries. Our best Hindi model achieves state of the art performance, and also achieves good performance on a closely related language, Punjabi, without modification.","authors":["Aryaman Arora","Luke Gessler","Nathan Schneider"],"demo_url":"","keywords":["Hindi conversion","schwa deletion","Supervised Schwas","rule-based fashion"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.696.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.696","similar_paper_uids":["main.696","main.81","srw.19","main.299","srw.129"],"title":"Supervised Grapheme-to-Phoneme Conversion of Orthographic Schwas in Hindi and Punjabi","tldr":"Hindi grapheme-to-phoneme (G2P) conversion is mostly trivial, with one exception: whether a schwa represented in the orthography is pronounced or unpronounced (deleted). Previous work has attempted to predict schwa deletion in a rule-based fashion us...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.696","id":"main.696","presentation_id":"38929177"},{"card_image_alt_text":"A representative figure from paper main.650","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.650.png","content":{"abstract":"Historical text normalization, the task of mapping historical word forms to their modern counterparts, has recently attracted a lot of interest (Bollmann, 2019; Tang et al., 2018; Lusetti et al., 2018; Bollmann et al., 2018;Robertson and Goldwater, 2018; Bollmannet al., 2017; Korchagina, 2017). Yet, virtually all approaches suffer from the two limitations: 1) They consider a fully supervised setup, often with impractically large manually normalized datasets; 2) Normalization happens on words in isolation. By utilizing a simple generative normalization model and obtaining powerful contextualization from the target-side language model, we train accurate models with unlabeled historical data. In realistic training scenarios, our approach often leads to reduction in manually normalized data at the same accuracy levels.","authors":["Peter Makarov","Simon Clematide"],"demo_url":"","keywords":["Semi-supervised Normalization","Historical normalization","mapping forms","generative model"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.650.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.650","similar_paper_uids":["main.650","main.132","main.191","srw.69","main.389"],"title":"Semi-supervised Contextual Historical Text Normalization","tldr":"Historical text normalization, the task of mapping historical word forms to their modern counterparts, has recently attracted a lot of interest (Bollmann, 2019; Tang et al., 2018; Lusetti et al., 2018; Bollmann et al., 2018;Robertson and Goldwater, 2...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.650","id":"main.650","presentation_id":"38929200"},{"card_image_alt_text":"A representative figure from paper main.732","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.732.png","content":{"abstract":"In many languages like Arabic, diacritics are used to specify pronunciations as well as meanings. Such diacritics are often omitted in written text, increasing the number of possible pronunciations and meanings for a word. This results in a more ambiguous text making computational processing on such text more difficult. Diacritic restoration is the task of restoring missing diacritics in the written text. Most state-of-the-art diacritic restoration models are built on character level information which helps generalize the model to unseen data, but presumably lose useful information at the word level. Thus, to compensate for this loss, we investigate the use of multi-task learning to jointly optimize diacritic restoration with related NLP problems namely word segmentation, part-of-speech tagging, and syntactic diacritization. We use Arabic as a case study since it has sufficient data resources for tasks that we consider in our joint modeling. Our joint models significantly outperform the baselines and are comparable to the state-of-the-art models that are more complex relying on morphological analyzers and/or a lot more data (e.g. dialectal data).","authors":["Sawsan Alqahtani","Ajay Mishra","Mona Diab"],"demo_url":"","keywords":["Diacritic Restoration","computational processing","restoring diacritics","NLP problems"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.732.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.732","similar_paper_uids":["main.732","main.736","main.603","main.735","main.645"],"title":"A Multitask Learning Approach for Diacritic Restoration","tldr":"In many languages like Arabic, diacritics are used to specify pronunciations as well as meanings. Such diacritics are often omitted in written text, increasing the number of possible pronunciations and meanings for a word. This results in a more ambi...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.732","id":"main.732","presentation_id":"38929167"},{"card_image_alt_text":"A representative figure from paper main.733","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.733.png","content":{"abstract":"Lexica distinguishing all morphologically related forms of each lexeme are crucial to many language technologies, yet building them is expensive. We propose a frugal paradigm completion approach that predicts all related forms in a morphological paradigm from as few manually provided forms as possible. It induces typological information during training which it uses to determine the best sources at test time. We evaluate our language-agnostic approach on 7 diverse languages. Compared to popular alternative approaches, ours reduces manual labor by 16-63% and is the most robust to typological variation.","authors":["Alexander Erdmann","Tom Kenter","Markus Becker","Christian Schallhart"],"demo_url":"","keywords":["Frugal Completion","language technologies","frugal approach","morphological paradigm"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.733.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.733","similar_paper_uids":["main.733","main.398","main.598","main.676","main.436"],"title":"Frugal Paradigm Completion","tldr":"Lexica distinguishing all morphologically related forms of each lexeme are crucial to many language technologies, yet building them is expensive. We propose a frugal paradigm completion approach that predicts all related forms in a morphological para...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.733","id":"main.733","presentation_id":"38928759"},{"card_image_alt_text":"A representative figure from paper main.595","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.595.png","content":{"abstract":"Fully supervised neural approaches have achieved significant progress in the task of Chinese word segmentation (CWS). Nevertheless, the performance of supervised models always drops gravely if the domain shifts due to the distribution gap across domains and the out of vocabulary (OOV) problem. In order to simultaneously alleviate the issues, this paper intuitively couples distant annotation and adversarial training for cross-domain CWS. 1) We rethink the essence of ``Chinese words'' and design an automatic distant annotation mechanism, which does not need any supervision or pre-defined dictionaries on the target domain. The method could effectively explore domain-specific words and distantly annotate the raw texts for the target domain. 2) We further develop a sentence-level adversarial training procedure to perform noise reduction and maximum utilization of the source domain information. Experiments on multiple real-world datasets across various domains show the superiority and robustness of our model, significantly outperforming previous state-of-the-arts cross-domain CWS methods.","authors":["Ning Ding","Dingkun Long","Guangwei Xu","Muhua Zhu","Pengjun Xie","Xiaobin Wang","Haitao Zheng"],"demo_url":"","keywords":["Coupling Annotation","Cross-Domain Segmentation","Chinese segmentation","Chinese CWS"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.595.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 07:00:00 GMT","session_name":"11B","start_time":"Wed, 08 Jul 2020 06:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.595","similar_paper_uids":["main.595","main.370","main.681","main.165","main.692"],"title":"Coupling Distant Annotation and Adversarial Training for Cross-Domain Chinese Word Segmentation","tldr":"Fully supervised neural approaches have achieved significant progress in the task of Chinese word segmentation (CWS). Nevertheless, the performance of supervised models always drops gravely if the domain shifts due to the distribution gap across doma...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.595","id":"main.595","presentation_id":"38928996"},{"card_image_alt_text":"A representative figure from paper main.594","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.594.png","content":{"abstract":"Polysynthetic languages have exceptionally large and sparse vocabularies, thanks to the number of morpheme slots and combinations in a word. This complexity, together with a general scarcity of written data, poses a challenge to the development of natural language technologies. To address this challenge, we offer linguistically-informed approaches for bootstrapping a neural morphological analyzer, and demonstrate its application to Kunwinjku, a polysynthetic Australian language. We generate data from a finite state transducer to train an encoder-decoder model. We improve the model by \"hallucinating\" missing linguistic structure into the training data, and by resampling from a Zipf distribution to simulate a more natural distribution of morphemes. The best model accounts for all instances of reduplication in the test set and achieves an accuracy of 94.7% overall, a 10 percentage point improvement over the FST baseline. This process demonstrates the feasibility of bootstrapping a neural morph analyzer from minimal resources.","authors":["William Lane","Steven Bird"],"demo_url":"","keywords":["Polysynthetic Analysis","Bootstrapping Techniques","natural technologies","linguistically-informed approaches"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.594.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 07:00:00 GMT","session_name":"11B","start_time":"Wed, 08 Jul 2020 06:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.594","similar_paper_uids":["main.594","main.389","main.596","main.22","main.695"],"title":"Bootstrapping Techniques for Polysynthetic Morphological Analysis","tldr":"Polysynthetic languages have exceptionally large and sparse vocabularies, thanks to the number of morpheme slots and combinations in a word. This complexity, together with a general scarcity of written data, poses a challenge to the development of na...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.594","id":"main.594","presentation_id":"38928893"},{"card_image_alt_text":"A representative figure from paper main.596","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.596.png","content":{"abstract":"This paper describes a language-independent model for fully unsupervised morphological analysis that exploits a universal framework leveraging morphological typology. By modeling morphological processes including suffixation, prefixation, infixation, and full and partial reduplication with constrained stem change rules, our system effectively constrains the search space and offers a wide coverage in terms of morphological typology. The system is tested on nine typologically and genetically diverse languages, and shows superior performance over leading systems. We also investigate the effect of an oracle that provides only a handful of bits per language to signal morphological type.","authors":["Hongzhi Xu","Jordan Kodner","Mitchell Marcus","Charles Yang"],"demo_url":"","keywords":["Unsupervised Morphology","fully analysis","language-independent model","universal framework"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.596.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 07:00:00 GMT","session_name":"11B","start_time":"Wed, 08 Jul 2020 06:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.596","similar_paper_uids":["main.596","main.598","main.594","main.389","main.27"],"title":"Modeling Morphological Typology for Unsupervised Learning of Language Morphology","tldr":"This paper describes a language-independent model for fully unsupervised morphological analysis that exploits a universal framework leveraging morphological typology. By modeling morphological processes including suffixation, prefixation, infixation,...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.596","id":"main.596","presentation_id":"38929259"},{"card_image_alt_text":"A representative figure from paper main.597","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/main.597.png","content":{"abstract":"The noun lexica of many natural languages are divided into several declension classes with characteristic morphological properties. Class membership is far from deterministic, but the phonological form of a noun and/or its meaning can often provide imperfect clues. Here, we investigate the strength of those clues. More specifically, we operationalize this by measuring how much information, in bits, we can glean about declension class from knowing the form and/or meaning of nouns. We know that form and meaning are often also indicative of grammatical gender\u2014which, as we quantitatively verify, can itself share information with declension class\u2014so we also control for gender. We find for two Indo-European languages (Czech and German) that form and meaning respectively share significant amounts of information with class (and contribute additional information above and beyond gender). The three-way interaction between class, form, and meaning (given gender) is also significant. Our study is important for two reasons: First, we introduce a new method that provides additional quantitative support for a classic linguistic finding that form and meaning are relevant for the classification of nouns into declensions. Secondly, we show not only that individual declensions classes vary in the strength of their clues within a language, but also that these variations themselves vary across languages.","authors":["Adina Williams","Tiago Pimentel","Hagen Blix","Arya D. McCarthy","Eleanor Chodroff","Ryan Cotterell"],"demo_url":"","keywords":["classification nouns","Declension Class","noun lexica","declension classes"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.597.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 07:00:00 GMT","session_name":"11B","start_time":"Wed, 08 Jul 2020 06:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.597","similar_paper_uids":["main.597","main.619","main.702","main.418","main.159"],"title":"Predicting Declension Class from Form and Meaning","tldr":"The noun lexica of many natural languages are divided into several declension classes with characteristic morphological properties. Class membership is far from deterministic, but the phonological form of a noun and/or its meaning can often provide i...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.597","id":"main.597","presentation_id":"38929092"},{"card_image_alt_text":"A representative figure from paper tacl.1759","card_image_path":"https://acl2020-public.s3.amazonaws.com/papers/tacl.1759.png","content":{"abstract":"We present methods for calculating a measure of phonotactic complexity\u2014bits per phoneme\u2014that permits a straightforward cross-linguistic comparison. When given a word, represented as a sequence of phonemic segments such as symbols in the international phonetic alphabet, and a statistical model trained on a sample of word types from the language, we can approximately measure bits per phoneme using the negative log-probability of that word under the model. This simple measure allows us to compare the entropy across languages, giving insight into how complex a language\u2019s phonotactics is. Using a collection of 1016 basic concept words across 106 languages, we demonstrate a very strong negative correlation of \u22120.74 between bits per phoneme and the average length of words.","authors":["Tiago Pimentel","Brian Roark","Ryan D. Cotterell"],"demo_url":"","keywords":["cross-linguistic comparison","statistical model","Phonotactic Complexity","phonemic segments"],"paper_type":"TACL","pdf_url":"https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00296","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 18:00:00 GMT","session_name":"14A","start_time":"Wed, 08 Jul 2020 17:00:00 GMT","zoom_link":""}],"share_url":"https://www.mitpressjournals.org/doi/10.1162/tacl_a_00296","similar_paper_uids":["tacl.1759","main.198","main.766","main.262","srw.90"],"title":"Phonotactic Complexity and Its Trade-offs","tldr":"We present methods for calculating a measure of phonotactic complexity\u2014bits per phoneme\u2014that permits a straightforward cross-linguistic comparison. When given a word, represented as a sequence of phonemic segments such as symbols in the international...","track":"Phonology, Morphology and Word Segmentation"},"forum":"tacl.1759","id":"tacl.1759","presentation_id":"38929489"}]
