[{"card_image_alt_text":"A representative figure from paper main.562","card_image_path":"static/images/papers/main.562.png","content":{"abstract":"Corpus query systems exist to address the multifarious information needs of any person interested in the content of annotated corpora. In this role they play an important part in making those resources usable for a wider audience. Over the past decades, several such query systems and languages have emerged, varying greatly in their expressiveness and technical details. This paper offers a broad overview of the history of corpora and corpus query tools. It focusses strongly on the query side and hints at exciting directions for future development.","authors":["Markus G\u00e4rtner","Kerstin Jung"],"demo_url":"","keywords":["Corpus systems","query systems","corpus tools","multifarious needs"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.562.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 06:00:00 GMT","session_name":"11A","start_time":"Wed, 08 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.562","similar_paper_uids":["main.562","demo.39","demo.44","main.622","main.116"],"title":"To Boldly Query What No One Has Annotated Before? The Frontiers of Corpus Querying","tldr":"Corpus query systems exist to address the multifarious information needs of any person interested in the content of annotated corpora. In this role they play an important part in making those resources usable for a wider audience. Over the past decad...","track":"Theme"},"forum":"main.562","id":"main.562","presentation_id":"38929384"},{"card_image_alt_text":"A representative figure from paper main.560","card_image_path":"static/images/papers/main.560.png","content":{"abstract":"Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the \"language agnostic\" status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.","authors":["Pratik Joshi","Sebastin Santy","Amar Budhiraja","Kalika Bali","Monojit Choudhury"],"demo_url":"","keywords":["NLP conferences","Language technologies","Linguistic Diversity","language status"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.560.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 06:00:00 GMT","session_name":"11A","start_time":"Wed, 08 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.560","similar_paper_uids":["main.560","main.464","main.485","main.150","demo.39"],"title":"The State and Fate of Linguistic Diversity and Inclusion in the NLP World","tldr":"Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and appli...","track":"Theme"},"forum":"main.560","id":"main.560","presentation_id":"38929069"},{"card_image_alt_text":"A representative figure from paper main.561","card_image_path":"static/images/papers/main.561.png","content":{"abstract":"In this paper, we trace the history of neural networks applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures. We focus on the importance of variable binding and its instantiation in attention-based models, and argue that Transformer is not a sequence model but an induced-structure model. This perspective leads to predictions of the challenges facing research in deep learning architectures for natural language understanding.","authors":["James Henderson"],"demo_url":"","keywords":["Deep Learning","natural tasks","natural understanding","neural networks"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.561.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 06:00:00 GMT","session_name":"11A","start_time":"Wed, 08 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.561","similar_paper_uids":["main.561","main.177","main.660","main.384","main.463"],"title":"The Unstoppable Rise of Computational Linguistics in Deep Learning","tldr":"In this paper, we trace the history of neural networks applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures. We focus on the importanc...","track":"Theme"},"forum":"main.561","id":"main.561","presentation_id":"38929007"},{"card_image_alt_text":"A representative figure from paper main.559","card_image_path":"static/images/papers/main.559.png","content":{"abstract":"While natural language understanding (NLU) is advancing rapidly, today's technology differs from human-like language understanding in fundamental ways, notably in its inferior efficiency, interpretability, and generalization. This work proposes an approach to representation and learning based on the tenets of embodied cognitive linguistics (ECL). According to ECL, natural language is inherently executable (like programming languages), driven by mental simulation and metaphoric mappings over hierarchical compositions of structures and schemata learned through embodied interaction. This position paper argues that the use of grounding by metaphoric reasoning and simulation will greatly benefit NLU systems, and proposes a system architecture along with a roadmap towards realizing this vision.","authors":["Ronen Tamari","Chen Shani","Tom Hope","Miriam R L Petruck","Omri Abend","Dafna Shahaf"],"demo_url":"","keywords":["Embodied Understanding","natural understanding","representation","NLU systems"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.559.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 06:00:00 GMT","session_name":"11A","start_time":"Wed, 08 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.559","similar_paper_uids":["main.559","main.163","main.542","main.63","main.683"],"title":"Language (Re)modelling: Towards Embodied Language Understanding","tldr":"While natural language understanding (NLU) is advancing rapidly, today's technology differs from human-like language understanding in fundamental ways, notably in its inferior efficiency, interpretability, and generalization. This work proposes an ap...","track":"Theme"},"forum":"main.559","id":"main.559","presentation_id":"38929397"},{"card_image_alt_text":"A representative figure from paper main.558","card_image_path":"static/images/papers/main.558.png","content":{"abstract":"Recent advances in pre-trained multilingual language models lead to state-of-the-art results on the task of quality estimation (QE) for machine translation. A carefully engineered ensemble of such models won the QE shared task at WMT19. Our in-depth analysis, however, shows that the success of using pre-trained language models for QE is over-estimated due to three issues we observed in current QE datasets: (i) The distributions of quality scores are imbalanced and skewed towards good quality scores; (iii) QE models can perform well on these datasets while looking at only source or translated sentences; (iii) They contain statistical artifacts that correlate well with human-annotated QE labels. Our findings suggest that although QE models might capture fluency of translated sentences and complexity of source sentences, they cannot model adequacy of translations effectively.","authors":["Shuo Sun","Francisco Guzm\u00e1n","Lucia Specia"],"demo_url":"","keywords":["Estimating Quality","quality estimation","machine translation","QE task"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.558.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 06:00:00 GMT","session_name":"11A","start_time":"Wed, 08 Jul 2020 05:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.558","similar_paper_uids":["main.558","main.114","main.321","main.113","main.253"],"title":"Are we Estimating or Guesstimating Translation Quality?","tldr":"Recent advances in pre-trained multilingual language models lead to state-of-the-art results on the task of quality estimation (QE) for machine translation. A carefully engineered ensemble of such models won the QE shared task at WMT19. Our in-depth ...","track":"Theme"},"forum":"main.558","id":"main.558","presentation_id":"38929307"},{"card_image_alt_text":"A representative figure from paper main.662","card_image_path":"static/images/papers/main.662.png","content":{"abstract":"In addition to the traditional task of machines answering questions, question answering (QA) research creates interesting, challenging questions that help systems how to answer questions and reveal the best systems. We argue that creating a QA dataset\u2014and the ubiquitous leaderboard that goes with it\u2014closely resembles running a trivia tournament: you write questions, have agents (either humans or machines) answer the questions, and declare a winner. However, the research community has ignored the hard-learned lessons from decades of the trivia community creating vibrant, fair, and effective question answering competitions. After detailing problems with existing QA datasets, we outline the key lessons\u2014removing ambiguity, discriminating skill, and adjudicating disputes---that can transfer to QA research and how they might be implemented.","authors":["Jordan Boyd-Graber","Benjamin B\u00f6rschinger"],"demo_url":"","keywords":["Question Answering","machines questions","QA","QA research"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.662.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.662","similar_paper_uids":["main.662","main.413","main.20","main.600","main.652"],"title":"What Question Answering can Learn from Trivia Nerds","tldr":"In addition to the traditional task of machines answering questions, question answering (QA) research creates interesting, challenging questions that help systems how to answer questions and reveal the best systems. We argue that creating a QA datase...","track":"Theme"},"forum":"main.662","id":"main.662","presentation_id":"38928685"},{"card_image_alt_text":"A representative figure from paper main.702","card_image_path":"static/images/papers/main.702.png","content":{"abstract":"Disparities in authorship and citations across genders can have substantial adverse consequences not just on the disadvantaged gender, but also on the field of study as a whole. In this work, we examine female first author percentages and the citations to their papers in Natural Language Processing. We find that only about 29% of first authors are female and only about 25% of last authors are female. Notably, this percentage has not improved since the mid 2000s. We also show that, on average, female first authors are cited less than male first authors, even when controlling for experience and area of research. We hope that recording citation and participation gaps across demographic groups will improve awareness of gender gaps and encourage more inclusiveness and fairness in research.","authors":["Saif M. Mohammad"],"demo_url":"","keywords":["Gender Gap","Natural Research","Natural Processing","citations"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.702.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.702","similar_paper_uids":["main.702","main.464","main.619","main.597","main.690"],"title":"Gender Gap in Natural Language Processing Research: Disparities in Authorship and Citations","tldr":"Disparities in authorship and citations across genders can have substantial adverse consequences not just on the disadvantaged gender, but also on the field of study as a whole. In this work, we examine female first author percentages and the citatio...","track":"Theme"},"forum":"main.702","id":"main.702","presentation_id":"38929185"},{"card_image_alt_text":"A representative figure from paper main.663","card_image_path":"static/images/papers/main.663.png","content":{"abstract":"Distributional semantic models have become a mainstay in NLP, providing useful features for downstream tasks. However, assessing long-term progress requires explicit long-term goals. In this paper, I take a broad linguistic perspective, looking at how well current models can deal with various semantic challenges. Given stark differences between models proposed in different subfields, a broad perspective is needed to see how we could integrate them. I conclude that, while linguistic insights can guide the design of model architectures, future progress will require balancing the often conflicting demands of linguistic expressiveness and computational tractability.","authors":["Guy Emerson"],"demo_url":"","keywords":["NLP","downstream tasks","assessing progress","Distributional Semantics"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.663.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.663","similar_paper_uids":["main.663","main.96","main.408","main.386","cl.1547"],"title":"What are the Goals of Distributional Semantics?","tldr":"Distributional semantic models have become a mainstay in NLP, providing useful features for downstream tasks. However, assessing long-term progress requires explicit long-term goals. In this paper, I take a broad linguistic perspective, looking at ho...","track":"Theme"},"forum":"main.663","id":"main.663","presentation_id":"38929194"},{"card_image_alt_text":"A representative figure from paper main.463","card_image_path":"static/images/papers/main.463.png","content":{"abstract":"The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as ``understanding'' language or capturing ``meaning''. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of ``Taking Stock of Where We've Been and Where We're Going'', we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.","authors":["Emily M. Bender","Alexander Koller"],"demo_url":"","keywords":["NLP tasks","natural understanding","large models","NLU"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.463.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.463","similar_paper_uids":["main.463","main.698","main.382","main.340","tacl.1756"],"title":"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data","tldr":"The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as ``understanding'' language or capturing ``meaning''. In this posi...","track":"Theme"},"forum":"main.463","id":"main.463","presentation_id":"38929214"},{"card_image_alt_text":"A representative figure from paper main.661","card_image_path":"static/images/papers/main.661.png","content":{"abstract":"Over its three decade history, speech translation has experienced several shifts in its primary research themes; moving from loosely coupled cascades of speech recognition and machine translation, to exploring questions of tight coupling, and finally to end-to-end models that have recently attracted much attention. This paper provides a brief survey of these developments, along with a discussion of the main challenges of traditional approaches which stem from committing to intermediate representations from the speech recognizer, and from training cascaded models separately towards different objectives. Recent end-to-end modeling techniques promise a principled way of overcoming these issues by allowing joint training of all model components and removing the need for explicit intermediate representations. However, a closer look reveals that many end-to-end models fall short of solving these issues, due to compromises made to address data scarcity. This paper provides a unifying categorization and nomenclature that covers both traditional and recent approaches and that may help researchers by highlighting both trade-offs and open research questions.","authors":["Matthias Sperber","Matthias Paulik"],"demo_url":"","keywords":["Speech Translation","speech recognition","machine translation","data scarcity"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.661.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.661","similar_paper_uids":["main.661","main.217","main.345","main.614","main.54"],"title":"Speech Translation and the End-to-End Promise: Taking Stock of Where We Are","tldr":"Over its three decade history, speech translation has experienced several shifts in its primary research themes; moving from loosely coupled cascades of speech recognition and machine translation, to exploring questions of tight coupling, and finally...","track":"Theme"},"forum":"main.661","id":"main.661","presentation_id":"38928786"},{"card_image_alt_text":"A representative figure from paper main.701","card_image_path":"static/images/papers/main.701.png","content":{"abstract":"Many tasks aim to measure machine reading comprehension (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key contributions. First, we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehension\u2014a \"Template of Understanding\"\u2014for a widely useful class of texts, namely short narratives. We then conduct an experiment that strongly suggests existing systems are not up to the task of narrative understanding as we define it.","authors":["Jesse Dunietz","Greg Burnham","Akash Bharadwaj","Owen Rambow","Jennifer Chu-Carroll","Dave Ferrucci"],"demo_url":"","keywords":["Machine Comprehension","Defining Comprehension","MRC","narrative understanding"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.701.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.701","similar_paper_uids":["main.701","main.507","main.211","main.247","main.654"],"title":"To Test Machine Comprehension, Start by Defining Comprehension","tldr":"Many tasks aim to measure machine reading comprehension (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key co...","track":"Theme"},"forum":"main.701","id":"main.701","presentation_id":"38928793"},{"card_image_alt_text":"A representative figure from paper main.700","card_image_path":"static/images/papers/main.700.png","content":{"abstract":"Most NLP models today treat language as universal, even though socio- and psycholingustic research shows that the communicated message is influenced by the characteristics of the speaker as well as the target audience. This paper surveys the landscape of personalization in natural language processing and related fields, and offers a path forward to mitigate the decades of deviation of the NLP tools from sociolingustic findings, allowing to flexibly process the ``natural'' language of each user rather than enforcing a uniform NLP treatment. It outlines a possible direction to incorporate these aspects into neural NLP models by means of socially contextual personalization, and proposes to shift the focus of our evaluation strategies accordingly.","authors":["Lucie Flek"],"demo_url":"","keywords":["NLP","natural fields","Contextually Models","NLP models"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.700.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.700","similar_paper_uids":["main.700","main.506","main.462","srw.36","main.463"],"title":"Returning the N to NLP: Towards Contextually Personalized Classification Models","tldr":"Most NLP models today treat language as universal, even though socio- and psycholingustic research shows that the communicated message is influenced by the characteristics of the speaker as well as the target audience. This paper surveys the landscap...","track":"Theme"},"forum":"main.700","id":"main.700","presentation_id":"38929062"},{"card_image_alt_text":"A representative figure from paper main.660","card_image_path":"static/images/papers/main.660.png","content":{"abstract":"It has been exactly a decade since the first establishment of SPMRL, a research initiative unifying multiple research efforts to address the peculiar challenges of Statistical Parsing for Morphologically-Rich Languages (MRLs). Here we reflect on parsing MRLs in that decade, highlight the solutions and lessons learned for the architectural, modeling and lexical challenges in the pre-neural era, and argue that similar challenges re-emerge in neural architectures for MRLs. We then aim to offer a climax, suggesting that incorporating symbolic ideas proposed in SPMRL terms into nowadays neural architectures has the potential to push NLP for MRLs to a new level. We sketch a strategies for designing Neural Models for MRLs (NMRL), and showcase preliminary support for these strategies via investigating the task of multi-tagging in Hebrew, a morphologically-rich, high-fusion, language.","authors":["Reut Tsarfaty","Dan Bareket","Stav Klein","Amit Seker"],"demo_url":"","keywords":["parsing MRLs","MRLs","NLP","multi-tagging"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.660.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.660","similar_paper_uids":["main.660","main.561","main.592","main.766","main.485"],"title":"From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of Parsing Morphologically-Rich Languages (MRLs)?","tldr":"It has been exactly a decade since the first establishment of SPMRL, a research initiative unifying multiple research efforts to address the peculiar challenges of Statistical Parsing for Morphologically-Rich Languages (MRLs). Here we reflect on pars...","track":"Theme"},"forum":"main.660","id":"main.660","presentation_id":"38928774"},{"card_image_alt_text":"A representative figure from paper main.462","card_image_path":"static/images/papers/main.462.png","content":{"abstract":"Human speakers have an extensive toolkit of ways to express themselves. In this paper, we engage with an idea largely absent from discussions of meaning in natural language understanding\u2014namely, that the way something is expressed reflects different ways of conceptualizing or construing the information being conveyed. We first define this phenomenon more precisely, drawing on considerable prior work in theoretical cognitive semantics and psycholinguistics. We then survey some dimensions of construed meaning and show how insights from construal could inform theoretical and practical work in NLP.","authors":["Sean Trott","Tiago Timponi Torrent","Nancy Chang","Nathan Schneider"],"demo_url":"","keywords":["NLP","natural understanding","theoretical semantics","construed meaning"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.462.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.462","similar_paper_uids":["main.462","main.463","main.700","main.405","main.485"],"title":"(Re)construing Meaning in NLP","tldr":"Human speakers have an extensive toolkit of ways to express themselves. In this paper, we engage with an idea largely absent from discussions of meaning in natural language understanding\u2014namely, that the way something is expressed reflects different ...","track":"Theme"},"forum":"main.462","id":"main.462","presentation_id":"38928895"},{"card_image_alt_text":"A representative figure from paper main.466","card_image_path":"static/images/papers/main.466.png","content":{"abstract":"Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rule-based and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we introduce the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an in-depth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github.com/thunlp/CLAIM.","authors":["Haoxi Zhong","Chaojun Xiao","Cunchao Tu","Tianyang Zhang","Zhiyuan Liu","Maosong Sun"],"demo_url":"","keywords":["Legal Intelligence","natural processing","Legal System","artificial intelligence"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.466.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.466","similar_paper_uids":["main.466","main.358","main.764","main.387","main.420"],"title":"How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence","tldr":"Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from ...","track":"Theme"},"forum":"main.466","id":"main.466","presentation_id":"38928947"},{"card_image_alt_text":"A representative figure from paper main.658","card_image_path":"static/images/papers/main.658.png","content":{"abstract":"We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.","authors":["Mikel Artetxe","Sebastian Ruder","Dani Yogatama","Gorka Labaka","Eneko Agirre"],"demo_url":"","keywords":["unsupervised learning","unsupervised setting","cross-lingual embeddings","deep pretraining"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.658.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.658","similar_paper_uids":["main.658","main.554","srw.137","main.421","main.510"],"title":"A Call for More Rigor in Unsupervised Cross-lingual Learning","tldr":"We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of th...","track":"Theme"},"forum":"main.658","id":"main.658","presentation_id":"38929161"},{"card_image_alt_text":"A representative figure from paper main.659","card_image_path":"static/images/papers/main.659.png","content":{"abstract":"Measuring what linguistic information is encoded in neural models of language has become popular in NLP. Researchers approach this enterprise by training \u201cprobes\u201d\u2014supervised models designed to extract linguistic structure from another model\u2019s output. One such probe is the structural probe (Hewitt and Manning, 2019), designed to quantify the extent to which syntactic information is encoded in contextualised word representations. The structural probe has a novel design, unattested in the parsing literature, the precise benefit of which is not immediately obvious. To explore whether syntactic probes would do better to make use of existing techniques, we compare the structural probe to a more traditional parser with an identical lightweight parameterisation. The parser outperforms structural probe on UUAS in seven of nine analysed languages, often by a substantial amount (e.g. by 11.1 points in English). Under a second less common metric, however, there is the opposite trend\u2014the structural probe outperforms the parser. This begs the question: which metric should we prefer?","authors":["Rowan Hall Maudslay","Josef Valvoda","Tiago Pimentel","Adina Williams","Ryan Cotterell"],"demo_url":"","keywords":["NLP","parsing literature","Parser","neural language"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.659.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 10:00:00 GMT","session_name":"12B","start_time":"Wed, 08 Jul 2020 09:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.659","similar_paper_uids":["main.659","main.420","main.383","srw.90","main.506"],"title":"A Tale of a Probe and a Parser","tldr":"Measuring what linguistic information is encoded in neural models of language has become popular in NLP. Researchers approach this enterprise by training \u201cprobes\u201d\u2014supervised models designed to extract linguistic structure from another model\u2019s output....","track":"Theme"},"forum":"main.659","id":"main.659","presentation_id":"38929294"},{"card_image_alt_text":"A representative figure from paper main.467","card_image_path":"static/images/papers/main.467.png","content":{"abstract":"While pretrained models such as BERT have shown large gains across natural language understanding tasks, their performance can be improved by further training the model on a data-rich intermediate task, before fine-tuning it on a target task. However, it is still poorly understood when and why intermediate-task training is beneficial for a given target task. To investigate this, we perform a large-scale study on the pretrained RoBERTa model with 110 intermediate-target task combinations. We further evaluate all trained models with 25 probing tasks meant to reveal the specific skills that drive transfer. We observe that intermediate tasks requiring high-level inference and reasoning abilities tend to work best. We also observe that target task performance is strongly correlated with higher-level abilities such as coreference resolution. However, we fail to observe more granular correlations between probing and target task performance, highlighting the need for further work on broad-coverage probing benchmarks. We also observe evidence that the forgetting of knowledge learned during pretraining may limit our analysis, highlighting the need for further work on transfer learning methods in these settings.","authors":["Yada Pruksachatkun","Jason Phang","Haokun Liu","Phu Mon Htut","Xiaoyi Zhang","Richard Yuanzhe Pang","Clara Vania","Katharina Kann","Samuel R. Bowman"],"demo_url":"","keywords":["Intermediate-Task Learning","natural tasks","data-rich task","intermediate-task training"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.467.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.467","similar_paper_uids":["main.467","main.740","main.207","main.383","main.497"],"title":"Intermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work?","tldr":"While pretrained models such as BERT have shown large gains across natural language understanding tasks, their performance can be improved by further training the model on a data-rich intermediate task, before fine-tuning it on a target task. However...","track":"Theme"},"forum":"main.467","id":"main.467","presentation_id":"38929152"},{"card_image_alt_text":"A representative figure from paper main.465","card_image_path":"static/images/papers/main.465.png","content":{"abstract":"This position paper describes and critiques the Pretraining-Agnostic Identically Distributed (PAID) evaluation paradigm, which has become a central tool for measuring progress in natural language understanding. This paradigm consists of three stages: (1) pre-training of a word prediction model on a corpus of arbitrary size; (2) fine-tuning (transfer learning) on a training set representing a classification task; (3) evaluation on a test set drawn from the same distribution as that training set. This paradigm favors simple, low-bias architectures, which, first, can be scaled to process vast amounts of data, and second, can capture the fine-grained statistical properties of a particular data set, regardless of whether those properties are likely to generalize to examples of the task outside the data set. This contrasts with humans, who learn language from several orders of magnitude less data than the systems favored by this evaluation paradigm, and generalize to new tasks in a consistent way. We advocate for supplementing or replacing PAID with paradigms that reward architectures that generalize as quickly and robustly as humans.","authors":["Tal Linzen"],"demo_url":"","keywords":["natural understanding","classification task","Pretraining-Agnostic paradigm","pre-training"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.465.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.465","similar_paper_uids":["main.465","main.197","main.89","main.212","main.62"],"title":"How Can We Accelerate Progress Towards Human-like Linguistic Generalization?","tldr":"This position paper describes and critiques the Pretraining-Agnostic Identically Distributed (PAID) evaluation paradigm, which has become a central tool for measuring progress in natural language understanding. This paradigm consists of three stages:...","track":"Theme"},"forum":"main.465","id":"main.465","presentation_id":"38929098"},{"card_image_alt_text":"A representative figure from paper main.698","card_image_path":"static/images/papers/main.698.png","content":{"abstract":"Building on Petroni et al. 2019, we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We find that PLMs do not distinguish between negated (``Birds cannot [MASK]'') and non-negated (``Birds can [MASK]'') cloze questions. (2) Mispriming. Inspired by priming methods in human psychology, we add ``misprimes'' to cloze questions (``Talk? Birds can [MASK]''). We find that PLMs are easily distracted by misprimes. These results suggest that PLMs still have a long way to go to adequately learn human-like factual knowledge.","authors":["Nora Kassner","Hinrich Sch\u00fctze"],"demo_url":"","keywords":["Pretrained Models","probing tasks","Negation","Pretrained Models"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.698.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.698","similar_paper_uids":["main.698","main.463","main.382","main.159","main.340"],"title":"Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly","tldr":"Building on Petroni et al. 2019, we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We find that PLMs do not distinguish between negated (``Birds cannot [MASK]'') and non-negated (`...","track":"Theme"},"forum":"main.698","id":"main.698","presentation_id":"38929168"},{"card_image_alt_text":"A representative figure from paper main.699","card_image_path":"static/images/papers/main.699.png","content":{"abstract":"The field of natural language processing is experiencing a period of unprecedented growth, and with it a surge of published papers. This represents an opportunity for us to take stock of how we cite the work of other researchers, and whether this growth comes at the expense of \"forgetting\" about older literature. In this paper, we address this question through bibliographic analysis. By looking at the age of outgoing citations in papers published at selected ACL venues between 2010 and 2019, we find that there is indeed a tendency for recent papers to cite more recent work, but the rate at which papers older than 15 years are cited has remained relatively stable.","authors":["Marcel Bollmann","Desmond Elliott"],"demo_url":"","keywords":["natural processing","bibliographic analysis","outgoing citations","ACL Anthology"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.699.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.699","similar_paper_uids":["main.699","main.464","demo.39","main.485","main.702"],"title":"On Forgetting to Cite Older Papers: An Analysis of the ACL Anthology","tldr":"The field of natural language processing is experiencing a period of unprecedented growth, and with it a surge of published papers. This represents an opportunity for us to take stock of how we cite the work of other researchers, and whether this gro...","track":"Theme"},"forum":"main.699","id":"main.699","presentation_id":"38929066"},{"card_image_alt_text":"A representative figure from paper main.464","card_image_path":"static/images/papers/main.464.png","content":{"abstract":"We extracted information from the ACL Anthology (AA) and Google Scholar (GS) to examine trends in citations of NLP papers. We explore questions such as: how well cited are papers of different types (journal articles, conference papers, demo papers, etc.)? how well cited are papers from different areas of within NLP? etc. Notably, we show that only about 56% of the papers in AA are cited ten or more times. CL Journal has the most cited papers, but its citation dominance has lessened in recent years. On average, long papers get almost three times as many citations as short papers; and papers on sentiment classification, anaphora resolution, and entity recognition have the highest median citations. The analyses presented here, and the associated dataset of NLP papers mapped to citations, have a number of uses including: understanding how the field is growing and quantifying the impact of different types of papers.","authors":["Saif M. Mohammad"],"demo_url":"","keywords":["NLP","AA","sentiment classification","anaphora resolution"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.464.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.464","similar_paper_uids":["main.464","demo.39","main.550","main.699","main.702"],"title":"Examining Citations of Natural Language Processing Literature","tldr":"We extracted information from the ACL Anthology (AA) and Google Scholar (GS) to examine trends in citations of NLP papers. We explore questions such as: how well cited are papers of different types (journal articles, conference papers, demo papers, e...","track":"Theme"},"forum":"main.464","id":"main.464","presentation_id":"38929236"},{"card_image_alt_text":"A representative figure from paper main.469","card_image_path":"static/images/papers/main.469.png","content":{"abstract":"Pre-trained visually grounded language models such as ViLBERT, LXMERT, and UNITER have achieved significant performance improvement on vision-and-language tasks but what they learn during pre-training remains unclear. In this work, we demonstrate that certain attention heads of a visually grounded language model actively ground elements of language to image regions. Specifically, some heads can map entities to image regions, performing the task known as entity grounding. Some heads can even detect the syntactic relations between non-entity words and image regions, tracking, for example, associations between verbs and regions corresponding to their arguments. We denote this ability as syntactic grounding. We verify grounding both quantitatively and qualitatively, using Flickr30K Entities as a testbed.","authors":["Liunian Harold Li","Mark Yatskar","Da Yin","Cho-Jui Hsieh","Kai-Wei Chang"],"demo_url":"","keywords":["vision-and-language tasks","pre-training","entity grounding","Pre-trained models"],"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.469.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.469","similar_paper_uids":["main.469","main.311","main.664","main.425","main.583"],"title":"What Does BERT with Vision Look At?","tldr":"Pre-trained visually grounded language models such as ViLBERT, LXMERT, and UNITER have achieved significant performance improvement on vision-and-language tasks but what they learn during pre-training remains unclear. In this work, we demonstrate tha...","track":"Theme"},"forum":"main.469","id":"main.469","presentation_id":"38928841"},{"card_image_alt_text":"A representative figure from paper main.468","card_image_path":"static/images/papers/main.468.png","content":{"abstract":"An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.","authors":["Deven Santosh Shah","H. Andrew Schwartz","Dirk Hovy"],"demo_url":"","keywords":["NLP","Natural Models","Conceptual Framework","mitigation techniques"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.468.pdf","sessions":[{"end_time":"Tue, 07 Jul 2020 18:00:00 GMT","session_name":"9A","start_time":"Tue, 07 Jul 2020 17:00:00 GMT","zoom_link":""},{"end_time":"Tue, 07 Jul 2020 21:00:00 GMT","session_name":"10A","start_time":"Tue, 07 Jul 2020 20:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.468","similar_paper_uids":["main.468","main.264","main.260","main.773","main.262"],"title":"Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview","tldr":"An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted indivi...","track":"Theme"},"forum":"main.468","id":"main.468","presentation_id":"38929459"},{"card_image_alt_text":"A representative figure from paper main.697","card_image_path":"static/images/papers/main.697.png","content":{"abstract":"In this theme paper, we focus on Automated Writing Evaluation (AWE), using Ellis Page\u2019s seminal 1966 paper to frame the presentation. We discuss some of the current frontiers in the field and offer some thoughts on the emergent uses of this technology.","authors":["Beata Beigman Klebanov","Nitin Madnani"],"demo_url":"","keywords":["Automated Writing","Automated Evaluation","Automated AWE","Automated"],"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.acl-main.697.pdf","sessions":[{"end_time":"Wed, 08 Jul 2020 14:00:00 GMT","session_name":"13B","start_time":"Wed, 08 Jul 2020 13:00:00 GMT","zoom_link":""},{"end_time":"Wed, 08 Jul 2020 22:00:00 GMT","session_name":"15B","start_time":"Wed, 08 Jul 2020 21:00:00 GMT","zoom_link":""}],"share_url":"https://www.aclweb.org/anthology/2020.acl-main.697","similar_paper_uids":["main.697","main.759","main.462","main.447","main.606"],"title":"Automated Evaluation of Writing \u2013 50 Years and Counting","tldr":"In this theme paper, we focus on Automated Writing Evaluation (AWE), using Ellis Page\u2019s seminal 1966 paper to frame the presentation. We discuss some of the current frontiers in the field and offer some thoughts on the emergent uses of this technolog...","track":"Theme"},"forum":"main.697","id":"main.697","presentation_id":"38929122"}]
