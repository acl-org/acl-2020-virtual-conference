


<!DOCTYPE html>
<html lang="en">
  <head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>


    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>

    <!-- https://developer.snapappointments.com/bootstrap-select/ -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/css/bootstrap-select.min.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/js/bootstrap-select.min.js"></script>

    <!-- Library libs -->
    <script src="static/js/typeahead.bundle.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
      href="static/css/Lato.css"
      rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet" />
    <link
      href="static/css/Cuprum.css"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/main.css" />
    <link rel="stylesheet" href="static/css/lazy_load.css" />
    <link rel="stylesheet" href="static/css/typeahead.css" />

    <title>ACL2020: Integrating Multimodal Information in Large Pretrained Transformers</title>
    
<meta name="citation_title" content="Integrating Multimodal Information in Large Pretrained Transformers" />

<meta name="citation_author" content="Wasifur Rahman" />

<meta name="citation_author" content="Md Kamrul Hasan" />

<meta name="citation_author" content="Sangwu Lee" />

<meta name="citation_author" content="AmirAli Bagher Zadeh" />

<meta name="citation_author" content="Chengfeng Mao" />

<meta name="citation_author" content="Louis-Philippe Morency" />

<meta name="citation_author" content="Ehsan Hoque" />

<meta name="citation_publication_date" content="July 2020" />
<meta name="citation_conference_title" content="The 58th Annual Meeting Of The Association For Computational Linguistics" />
<meta name="citation_inbook_title" content="Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics" />
<meta name="citation_abstract" content="Recent Transformer-based contextual word representations, including BERT and XLNet, have shown state-of-the-art performance in multiple disciplines within NLP. Fine-tuning the trained contextual models on task-specific datasets has been the key to achieving superior performance downstream. While fine-tuning these pre-trained models is straightforward for lexical applications (applications with only language modality), it is not trivial for multimodal language (a growing area in NLP focused on modeling face-to-face communication). More specifically, this is due to the fact that pre-trained models don&#39;t have the necessary components to accept two extra modalities of vision and acoustic. In this paper, we proposed an attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG allows BERT and XLNet to accept multimodal nonverbal data during fine-tuning. It does so by generating a shift to internal representation of BERT and XLNet; a shift that is conditioned on the visual and acoustic modalities. In our experiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for multimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly boosts the sentiment analysis performance over previous baselines as well as language-only fine-tuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet achieves human-level multimodal sentiment analysis performance for the first time in the NLP community." />

<meta name="citation_keywords" content="NLP" />

<meta name="citation_keywords" content="lexical applications" />

<meta name="citation_keywords" content="modeling communication" />

<meta name="citation_keywords" content="multimodal analysis" />

<meta name="citation_pdf_url" content="https://www.aclweb.org/anthology/2020.acl-main.214.pdf" />


    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon/favicon-16x16.png">
    <link rel="manifest" href="static/favicon/site.webmanifest">
    <link rel="mask-icon" href="static/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="static/favicon/favicon.ico">
    <meta name="msapplication-TileColor" content="#2d89ef">
    <meta name="msapplication-config" content="static/favicon/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
  </head>

  <body>
    <!-- NAV -->
    
    

    <nav
      class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
      id="main-nav"
    >
      <div class="container">
        <a class="navbar-brand" href="index.html">
          <img
             class="logo" src="static/images/acl2020/acl-logo.png"
             height="45px"
             width="auto"
          />
        </a>
        
        <a class="navbar-brand" href="index.html">ACL2020</a>
        
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarNav"
          aria-controls="navbarNav"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div
          class="collapse navbar-collapse text-right flex-grow-1"
          id="navbarNav"
        >
          <ul class="navbar-nav ml-auto">
            
            <li class="nav-item ">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="schedule.html">Schedule</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="livestream.html">Livestream</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="plenary_sessions.html">Plenary</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="papers.html">Papers</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="tutorials.html">Tutorials</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="workshops.html">Workshops</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="sponsors.html">Sponsors</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="organizers.html">Organizers</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="about.html">Help</a>
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
    

    
    <!-- User Overrides -->
     

    <div class="container">
      <!-- Heading -->
      <div class="heading">
         
      </div>
      <div class="tabs pt-3">
      <!-- Tabs -->
      <div class="tabs pt-3">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3">
  <div class="card-header">
    <h2 class="card-title main-title text-center" style="color: black">
      Integrating Multimodal Information in Large Pretrained Transformers
    </h2>
    <h3 class="card-subtitle mb-2 text-muted text-center">
      
      <a href="papers.html?filter=authors&search=Wasifur Rahman" class="text-primary"
        >Wasifur Rahman</a
      >,
      
      <a href="papers.html?filter=authors&search=Md Kamrul Hasan" class="text-primary"
        >Md Kamrul Hasan</a
      >,
      
      <a href="papers.html?filter=authors&search=Sangwu Lee" class="text-primary"
        >Sangwu Lee</a
      >,
      
      <a href="papers.html?filter=authors&search=AmirAli Bagher Zadeh" class="text-primary"
        >AmirAli Bagher Zadeh</a
      >,
      
      <a href="papers.html?filter=authors&search=Chengfeng Mao" class="text-primary"
        >Chengfeng Mao</a
      >,
      
      <a href="papers.html?filter=authors&search=Louis-Philippe Morency" class="text-primary"
        >Louis-Philippe Morency</a
      >,
      
      <a href="papers.html?filter=authors&search=Ehsan Hoque" class="text-primary"
        >Ehsan Hoque</a
      >
      
    </h3>
   
    <div class="text-center p-3">
      <a class="card-link" data-toggle="collapse" role="button" href="#details">
        Abstract
      </a>
      
      <a class="card-link" target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.214.pdf">
        Paper
      </a>
      
      
      
      
      <!-- Sharing options -->
      <a class="a2a_dd card-link" data-a2a-url="https://www.aclweb.org/anthology/2020.acl-main.214">Share</a>
      <script async src="https://static.addtoany.com/menu/page.js"></script>
  <script>
    var a2a_config = a2a_config || {};
    a2a_config.onclick = 1;
    a2a_config.num_services = 6;
    a2a_config.prioritize = ["twitter", "email", "facebook", "reddit", "linkedin", "copy_link"];
    a2a_config.no3p = true; //disable 3rd party cookies-limits some functionality
    a2a_config.templates.twitter = {hashtags: "acl2020nlp,ACL2020"};
  </script>
      
    </div>
    <p class="card-text text-center h5">

     <a href="papers.html?track=Speech and Multimodality" class ="badge badge-pill badge-primary" target="_blank">Speech and Multimodality</a>
     <span class="badge badge-secondary">Long Paper</span>
    </p>

    
  <div class="text-center text-muted text-monospace">
  <div class="paper-session-times">
  Session 4A: Jul 6
  <span class="session_times">(17:00-18:00 GMT)</span>

  

  
  </div>
  </div>

  <div class="text-center text-muted text-monospace">
  <div class="paper-cal-links">
  <img src="static/images/calendar.svg" class="paper-detail-calendar" height="24px">
  <span id="session-cal-link-1"></span>
  </div>
  </div>

  <div class="text-center text-muted text-monospace">
  <div class="paper-session-times">
  Session 5A: Jul 6
  <span class="session_times">(20:00-21:00 GMT)</span>

  

  
  </div>
  </div>

  <div class="text-center text-muted text-monospace">
  <div class="paper-cal-links">
  <img src="static/images/calendar.svg" class="paper-detail-calendar" height="24px">
  <span id="session-cal-link-2"></span>
  </div>
  </div>


<script src="static/js/add-to-calendar.js"></script>
<script>

  let ouicalData;
  let targetNode;
  let calendarNodeInner;
  let calendarNodeSpan;
  let parser = new DOMParser();
  let calendarNames = Array("google", "off365", "outlook", "ical");

  
    // create a calendar by hand
    ouicalData = addToCalendarData({
      options: {
        class: 'my-class',
        id: 'my-id'                               // If you don't pass an id, one will be generated for you.
      },
      data: {
        title: 'Integrating Multimodal Information in Large Pretrained Transformers'.replace("#", " "),

        // Event start date
        start: new Date("2020-07-06T17:00:00"),
        end: new Date("2020-07-06T18:00:00"),
        // duration: 120,                           // Event duration (IN MINUTES)
        // allday: true,														// Override end time, duration and timezone, triggers 'all day'

        // Event timezone. Will convert the given time to that zone
        timezone: 'UTC',
        // Event Address
        

        // Event Description
        // NOTE: Cannot use abstract because of it is multi-line. Need to format it.
        description: 'https://virtual.acl2020.org/paper_main.214.html'
      }
    });

    targetNode = document.querySelector('#session-cal-link-1');
    for (const name of calendarNames) {
      calendarNodeInner = parser.parseFromString(ouicalData[name], "text/html");
      calendarNodeSpan = document.createElement("span");
      calendarNodeSpan.setAttribute("style", "padding: 2px");

      const openBracket = document.createElement("span");
      openBracket.setAttribute("aria-hidden","true");
      openBracket.innerHTML = "[";
      calendarNodeSpan.appendChild(openBracket);

      calendarNodeSpan.appendChild(calendarNodeInner.getElementsByTagName("a")[0]);

      const closeBracket = document.createElement("span");
      closeBracket.setAttribute("aria-hidden","true");
      closeBracket.innerHTML = "]";
      calendarNodeSpan.appendChild(closeBracket);

      targetNode.appendChild(calendarNodeSpan);
    }
  
    // create a calendar by hand
    ouicalData = addToCalendarData({
      options: {
        class: 'my-class',
        id: 'my-id'                               // If you don't pass an id, one will be generated for you.
      },
      data: {
        title: 'Integrating Multimodal Information in Large Pretrained Transformers'.replace("#", " "),

        // Event start date
        start: new Date("2020-07-06T20:00:00"),
        end: new Date("2020-07-06T21:00:00"),
        // duration: 120,                           // Event duration (IN MINUTES)
        // allday: true,														// Override end time, duration and timezone, triggers 'all day'

        // Event timezone. Will convert the given time to that zone
        timezone: 'UTC',
        // Event Address
        

        // Event Description
        // NOTE: Cannot use abstract because of it is multi-line. Need to format it.
        description: 'https://virtual.acl2020.org/paper_main.214.html'
      }
    });

    targetNode = document.querySelector('#session-cal-link-2');
    for (const name of calendarNames) {
      calendarNodeInner = parser.parseFromString(ouicalData[name], "text/html");
      calendarNodeSpan = document.createElement("span");
      calendarNodeSpan.setAttribute("style", "padding: 2px");

      const openBracket = document.createElement("span");
      openBracket.setAttribute("aria-hidden","true");
      openBracket.innerHTML = "[";
      calendarNodeSpan.appendChild(openBracket);

      calendarNodeSpan.appendChild(calendarNodeInner.getElementsByTagName("a")[0]);

      const closeBracket = document.createElement("span");
      closeBracket.setAttribute("aria-hidden","true");
      closeBracket.innerHTML = "]";
      calendarNodeSpan.appendChild(closeBracket);

      targetNode.appendChild(calendarNodeSpan);
    }
  
</script>

  </div>
</div>

<div id="details" class="pp-card m-3 collapse">
  <div class="card-body">
    <div class="card-text">
      <div id="abstractExample">
        <span class="font-weight-bold">Abstract:</span>
        Recent Transformer-based contextual word representations, including BERT and XLNet, have shown state-of-the-art performance in multiple disciplines within NLP. Fine-tuning the trained contextual models on task-specific datasets has been the key to achieving superior performance downstream. While fine-tuning these pre-trained models is straightforward for lexical applications (applications with only language modality), it is not trivial for multimodal language (a growing area in NLP focused on modeling face-to-face communication). More specifically, this is due to the fact that pre-trained models don&#39;t have the necessary components to accept two extra modalities of vision and acoustic. In this paper, we proposed an attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG allows BERT and XLNet to accept multimodal nonverbal data during fine-tuning. It does so by generating a shift to internal representation of BERT and XLNet; a shift that is conditioned on the visual and acoustic modalities. In our experiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for multimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly boosts the sentiment analysis performance over previous baselines as well as language-only fine-tuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet achieves human-level multimodal sentiment analysis performance for the first time in the NLP community.
      </div>
    </div>
  </div>
</div>

<div class="container" style="background-color:white; padding: 0px;">
  <div class="text-muted text-center">
    You can open the
    <a href="https://slideslive.com/38929139" target="_blank">pre-recorded video</a>
    
    in a separate window.
    

  </div>
  <div class="row m-2">
    <!-- Slides Live-->
    <div class="col-md-12 col-xs-12 my-auto p-2" >
      <div id="presentation-embed" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed', {
        presentationId: '38929139',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 500,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>

      <div class="text-muted">
      NOTE: The SlidesLive video may display a random order of the authors.
      The correct author list is shown at the top of this webpage.
      </div>
    </div>

    <!-- Chat (disabled) -->
    
  </div>
</div>




<div class="my-3"></div>
<div class="row p-4">
  <div class="col-12 bd-content">
    <h1 class="text-center">Similar Papers</h1>
  </div>
</div>
<p></p>
<div class="container" >
  <div class="row">
  
    <div class="col-md-4 col-xs-6">
      <div class="pp-card" >
        <div class="pp-card-header" class="text-muted">
          <a href="paper_srw.79.html" class="text-muted">
            <h5 class="card-title" align="center">Transferring Monolingual Model to Low-Resource Language: The Case of Tigrinya</h5>
          </a>
          <h6 class="card-subtitle text-muted" align="center">
             
             Abrhalei Frezghi Tela,
             
             Abraham Woubie Zewoudie,
             
             Ville Hautamäki,
             
          </h6>
          <center><img class="cards_img" src="static/images/papers/srw.79.png" alt="A representative figure from paper srw.79" width="80%"/></center>
        </div>
      </div>
    </div>
  
    <div class="col-md-4 col-xs-6">
      <div class="pp-card" >
        <div class="pp-card-header" class="text-muted">
          <a href="paper_main.197.html" class="text-muted">
            <h5 class="card-title" align="center">SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization</h5>
          </a>
          <h6 class="card-subtitle text-muted" align="center">
             
             Haoming Jiang,
             
             Pengcheng He,
             
             Weizhu Chen,
             
             Xiaodong Liu,
             
             Jianfeng Gao,
             
             Tuo Zhao,
             
          </h6>
          <center><img class="cards_img" src="static/images/papers/main.197.png" alt="A representative figure from paper main.197" width="80%"/></center>
        </div>
      </div>
    </div>
  
    <div class="col-md-4 col-xs-6">
      <div class="pp-card" >
        <div class="pp-card-header" class="text-muted">
          <a href="paper_main.314.html" class="text-muted">
            <h5 class="card-title" align="center">Do you have the right scissors? Tailoring Pre-trained Language Models via Monte-Carlo Methods</h5>
          </a>
          <h6 class="card-subtitle text-muted" align="center">
             
             Ning Miao,
             
             Yuxuan Song,
             
             Hao Zhou,
             
             Lei Li,
             
          </h6>
          <center><img class="cards_img" src="static/images/papers/main.314.png" alt="A representative figure from paper main.314" width="80%"/></center>
        </div>
      </div>
    </div>
  
    <div class="col-md-4 col-xs-6">
      <div class="pp-card" >
        <div class="pp-card-header" class="text-muted">
          <a href="paper_main.357.html" class="text-muted">
            <h5 class="card-title" align="center">Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning</h5>
          </a>
          <h6 class="card-subtitle text-muted" align="center">
             
             Alexandre Tamborrino,
             
             Nicola Pellicanò,
             
             Baptiste Pannier,
             
             Pascal Voitot,
             
             Louise Naudin,
             
          </h6>
          <center><img class="cards_img" src="static/images/papers/main.357.png" alt="A representative figure from paper main.357" width="80%"/></center>
        </div>
      </div>
    </div>
  
  </div>
</div>

<script src="static/js/time-extend.js"></script>
<script>
  $(document).ready(()=>{
    add_local_tz('.session_times');
  })
</script>


      </div>
    </div>
    
    

    <!-- Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=UA-171494682-1"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "UA-171494682-1");
    </script>

    <!-- Footer -->
    <footer class="footer bg-light p-4">
      <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2020 Association for Computational Linguistics</p>
      </div>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });
      });
    </script>
    <script src="static/js/lazy_load.js"></script>
    
  </body>
</html>